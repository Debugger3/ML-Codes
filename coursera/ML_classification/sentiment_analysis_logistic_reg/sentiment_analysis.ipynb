{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sframe\n",
    "import string\n",
    "import pandas\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(None, string.punctuation)\n",
    "\n",
    "products = sframe.SFrame('amazon_baby.gl/')\n",
    "products = products.fillna('review',{'review':''})  # fill in N/A's in the review column\n",
    "products = products[products['rating'] != 3]\n",
    "products['review_clean'] = products['review'].apply(remove_punctuation) #creates a new column\n",
    "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3 else -1)\n",
    "\n",
    "#print products\n",
    "#products.print_rows(num_rows=1)\n",
    "#products.print_rows(num_rows=1,num_columns=4)\n",
    "#print products[products['sentiment']==-1]\n",
    "\n",
    "\n",
    "train_data, test_data = products.random_split(.8, seed=1)\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "# Use this token pattern to keep single-letter words\n",
    "# First, learn vocabulary from the training data and assign columns to words\n",
    "# Then convert the training data into a sparse matrix\n",
    "train_matrix = vectorizer.fit_transform(train_data['review_clean'])\n",
    "# Second, convert the test data into a sparse matrix, using the same word-column mapping\n",
    "\n",
    "test_matrix = vectorizer.transform(test_data['review_clean'])\n",
    "#print train_matrix.shape\n",
    "log_reg=linear_model.LogisticRegression()\n",
    "\n",
    "log_reg.fit(train_matrix,train_data['sentiment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85830\n"
     ]
    }
   ],
   "source": [
    "count=(log_reg.coef_>=0).sum()\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.60106442  -3.15214773 -10.42523329]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_test_data = test_data[10:13]\n",
    "#print sample_test_data\n",
    "sample_test_matrix = vectorizer.transform(sample_test_data['review_clean'])\n",
    "scores = log_reg.decision_function(sample_test_matrix)\n",
    "print scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "test_result=log_reg.predict_proba(sample_test_matrix)\n",
    "tmp=test_result[:,1]\n",
    "tmp=list(tmp)\n",
    "print tmp.index(min(tmp))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+-----+\n",
      "|              name             | ... |\n",
      "+-------------------------------+-----+\n",
      "| Baby Einstein Around The W... | ... |\n",
      "| Fisher-Price Cradle 'N Swi... | ... |\n",
      "| P'Kolino Silly Soft Seatin... | ... |\n",
      "| Evenflo X Sport Plus Conve... | ... |\n",
      "| Baby Jogger City Mini GT S... | ... |\n",
      "| Graco Pack 'n Play Element... | ... |\n",
      "| Infantino Wrap and Tie Bab... | ... |\n",
      "| Diono RadianRXT Convertibl... | ... |\n",
      "| Evenflo 6 Pack Classic Gla... | ... |\n",
      "| Roan Rocco Classic Pram St... | ... |\n",
      "| Simple Wishes Hands-Free B... | ... |\n",
      "| Freemie Hands-Free Conceal... | ... |\n",
      "| Mamas &amp; Papas 2014 Urb... | ... |\n",
      "| Britax 2012 B-Agile Stroll... | ... |\n",
      "| Buttons Cloth Diaper Cover... | ... |\n",
      "| Graco FastAction Fold Jogg... | ... |\n",
      "| Britax Decathlon Convertib... | ... |\n",
      "| Ikea 36 Pcs Kalas Kids Pla... | ... |\n",
      "| Summer Infant Wide View Di... | ... |\n",
      "| Baby Jogger City Mini GT D... | ... |\n",
      "+-------------------------------+-----+\n",
      "[33336 rows x 6 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_result=log_reg.predict_proba(test_matrix)\n",
    "test_data['prob']=test_result[:,1];\n",
    "test_sort_data=test_data.sort('prob',ascending=0)\n",
    "test_sort_data.print_rows(num_rows=20, num_columns=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+-----+\n",
      "|              name             | ... |\n",
      "+-------------------------------+-----+\n",
      "| Fisher-Price Ocean Wonders... | ... |\n",
      "| Levana Safe N'See Digital ... | ... |\n",
      "| Safety 1st Exchangeable Ti... | ... |\n",
      "| Adiri BPA Free Natural Nur... | ... |\n",
      "| VTech Communications Safe ... | ... |\n",
      "| The First Years True Choic... | ... |\n",
      "| Safety 1st High-Def Digita... | ... |\n",
      "| Cloth Diaper Sprayer--styl... | ... |\n",
      "| Motorola Digital Video Bab... | ... |\n",
      "| Philips AVENT Newborn Star... | ... |\n",
      "| Ellaroo Mei Tai Baby Carri... | ... |\n",
      "| Cosco Alpha Omega Elite Co... | ... |\n",
      "| Peg-Perego Tatamia High Ch... | ... |\n",
      "| Belkin WeMo Wi-Fi Baby Mon... | ... |\n",
      "| Chicco Cortina KeyFit 30 T... | ... |\n",
      "| NUK Cook-n-Blend Baby Food... | ... |\n",
      "| VTech Communications Safe ... | ... |\n",
      "| Safety 1st Deluxe 4-in-1 B... | ... |\n",
      "| Thirsties Hemp Inserts 2 P... | ... |\n",
      "| Regalo My Cot Portable Bed... | ... |\n",
      "+-------------------------------+-----+\n",
      "[4597 rows x 6 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sort_data=test_data.sort('prob',ascending=1)\n",
    "test_sort_data=test_sort_data[test_sort_data['prob']<0.5]\n",
    "test_sort_data.print_rows(num_rows=20, num_columns=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93\n"
     ]
    }
   ],
   "source": [
    "test_result=log_reg.predict(test_matrix)\n",
    "#print test_result\n",
    "test_data['pred']=test_result\n",
    "accuracy=((test_data['pred']==test_data['sentiment']).sum())/float(test_data.num_rows())\n",
    "print round(accuracy,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97\n"
     ]
    }
   ],
   "source": [
    "train_result=log_reg.predict(train_matrix)\n",
    "#print test_result\n",
    "train_data['pred']=train_result\n",
    "accuracy=((train_data['pred']==train_data['sentiment']).sum())/float(train_data.num_rows())\n",
    "print round(accuracy,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']\n",
    "vectorizer_word_subset = CountVectorizer(vocabulary=significant_words) # limit to 20 words\n",
    "train_matrix_word_subset = vectorizer_word_subset.fit_transform(train_data['review_clean'])\n",
    "test_matrix_word_subset = vectorizer_word_subset.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model=linear_model.LogisticRegression()\n",
    "simple_model.fit(train_matrix_word_subset,train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_model_coef_table = sframe.SFrame({'word':significant_words,\n",
    "                                         'coefficient':simple_model.coef_.flatten()})\n",
    "#print simple_model_coef_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "simple_model_coef_table=simple_model_coef_table.sort('coefficient',ascending=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "+-----------------+---------+\n",
      "|   coefficient   |   word  |\n",
      "+-----------------+---------+\n",
      "|  1.67307389259  |  loves  |\n",
      "|  1.50981247669  | perfect |\n",
      "|  1.36368975931  |   love  |\n",
      "|  1.19253827349  |   easy  |\n",
      "|  0.943999590572 |  great  |\n",
      "|  0.520185762718 |  little |\n",
      "|  0.503760457768 |   well  |\n",
      "|  0.190908572064 |   able  |\n",
      "|  0.085512779463 |   old   |\n",
      "| 0.0588546711528 |   car   |\n",
      "+-----------------+---------+\n",
      "[? rows x 2 columns]\n",
      "Note: Only the head of the SFrame is printed. This SFrame is lazily evaluated.\n",
      "You can use len(sf) to force materialization.\n"
     ]
    }
   ],
   "source": [
    "count=(simple_model_coef_table['coefficient']>0).sum()\n",
    "print count\n",
    "print simple_model_coef_table[simple_model_coef_table['coefficient']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87\n"
     ]
    }
   ],
   "source": [
    "train_result=simple_model.predict(train_matrix_word_subset)\n",
    "train_data['pred']=train_result\n",
    "accuracy=((train_data['pred']==train_data['sentiment']).sum())/float(train_data.num_rows())\n",
    "print round(accuracy,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87\n"
     ]
    }
   ],
   "source": [
    "test_result=simple_model.predict(test_matrix_word_subset)\n",
    "test_data['pred']=test_result\n",
    "accuracy=((test_data['pred']==test_data['sentiment']).sum())/float(test_data.num_rows())\n",
    "print round(accuracy,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_matrix_word_subset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9a986124323b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdummy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdummy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDummyClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_matrix_word_subset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentiment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtest_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_matrix_word_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pred'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_matrix_word_subset' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import dummy\n",
    "dum=dummy.DummyClassifier()\n",
    "dum.fit(train_matrix_word_subset,train_data['sentiment'])\n",
    "test_result=dum.predict(test_matrix_word_subset)\n",
    "test_data['pred']=test_result\n",
    "accuracy=((test_data['pred']==test_data['sentiment']).sum())/float(test_data.num_rows())\n",
    "print round(accuracy,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
